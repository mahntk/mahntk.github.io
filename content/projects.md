---
title: "Titanic â€“ Machine Learning from Disaster"
date: 2025-02-25
summary: "Ein Machine-Learning-Projekt zur Vorhersage der Ãœberlebenschancen von Titanic-Passagieren mit Fokus auf Datenanalyse, Feature Engineering und Modellauswahl."
tags: [Machine Learning, KI, Python, Scikit-Learn, Titanic]
categories: [KI-Projekt]
thumbnail: https://mahntk.github.io/uploads/titanic.jpg
links:
  - icon: kaggle
    icon_pack: fab
    name: Titanic Dataset (Kaggle)
    url: https://www.kaggle.com/competitions/titanic/overview
---

### ğŸ§  Titanic â€“ Machine Learning from Disaster

In diesem KI-Projekt habe ich gemeinsam mit meinem Team den berÃ¼hmten **Titanic-Datensatz** aus Kaggle analysiert, um die **Ãœberlebenswahrscheinlichkeit von Passagieren vorherzusagen**.

#### ğŸ” Vorgehensweise:
- **Datenvorverarbeitung:** Umgang mit fehlenden Werten (Median, lineare Regression), Entfernung irrelevanter Spalten, Umwandlung kategorialer Daten in numerische Form.
- **Datenanalyse:** Untersuchung der Korrelationen â€“ etwa Geschlecht, Ticketklasse und Preis als starke PrÃ¤diktoren fÃ¼r Ãœberleben.
- **Feature Engineering:** Neue Merkmale wie `FamilySize`, `IsAloneTicket` und `TicketFrequency` wurden erstellt, um die Modellleistung zu verbessern.

#### ğŸ§ª Modellierung:
Es wurden drei verschiedene Algorithmen implementiert:
- **Naive Bayes:** Einfach und schnell, aber sensibel gegenÃ¼ber Annahmen.
- **Logistische Regression:** Gute Balance aus Genauigkeit und Interpretierbarkeit.
- **K-Nearest Neighbors (KNN):** Sehr gute Performance mit optimalem `k` durch Grid Search.

#### âš™ï¸ Ergebnisse:
| Modell                | Genauigkeit |
|-----------------------|-------------|
| **KNN (k=10)**        | **83.62â€¯%** |
| Logistische Regression| 80.62â€¯%     |
| Naive Bayes           | 78.71â€¯%     |

#### ğŸ“Š Visualisierung:

![Modellvergleich](https://mahntk.github.io/uploads/modellvergleich_gridsearch.png)

![Ãœberlebensrate](https://mahntk.github.io/uploads/ueberlebensrate.png)

![Korrelationen](https://mahntk.github.io/uploads/korrelation.png)



#### ğŸ“š Learnings:
- **Feature Engineering** hatte einen groÃŸen Einfluss auf die ModellqualitÃ¤t.
- **KNN** zeigte das beste Ergebnis mit sorgfÃ¤ltiger Merkmalsauswahl und Tuning.
- Weitere Verbesserungen wÃ¤ren durch Modelle wie **Random Forests** oder **Ensemble-Methoden** mÃ¶glich.

> ğŸ‘¥ Team: Amirmahan Tajik, Christian Reikischke, Helene Nicolai, Marharyta Horak, Merna Mohsen  
> ğŸ”— [Zum Datensatz auf Kaggle](https://www.kaggle.com/competitions/titanic/overview)
---